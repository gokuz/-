<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title>抓取CNVD漏洞信息并存入MYSQL数据库 | Seeper Blog</title><meta name="description" content="抓取CNVD漏洞信息并存入MYSQL数据库 - null"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" href="/css/theme.css"><link rel="search" type="application/opensearchdescription+xml" href="/atom.xml" title="Seeper Blog"><link rel="stylesheet" href="/css/font-awesome.min.css"></head><body><div class="wrap"><header><h1 class="branding"><a href="/" title="Seeper Blog"><img class="logo-image" src="/favicon.ico" alt="logo"></a></h1><ul class="nav nav-list"><li class="nav-list-item"><!--a.nav-list-link(class={active: act} href=url_for(value), target=tar)--><a class="nav-list-link" href="/" target="_self">首页</a></li><li class="nav-list-item"><!--a.nav-list-link(class={active: act} href=url_for(value), target=tar)--><a class="nav-list-link" href="/archives" target="_self">归档</a></li><li class="nav-list-item"><!--a.nav-list-link(class={active: act} href=url_for(value), target=tar)--><a class="nav-list-link" href="/tags" target="_self">标签</a></li><li class="nav-list-item"><!--a.nav-list-link(class={active: act} href=url_for(value), target=tar)--><a class="nav-list-link" href="/about" target="_self">关于</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">抓取CNVD漏洞信息并存入MYSQL数据库</h1><p class="post-info"><i class="fa fa-calendar">&nbsp;</i>2017-06-17&nbsp;| <i class="fa fa-tags">&nbsp;</i><a class="post-category-link" href="https://github.com/wwwuxt">coder</a>&nbsp;| <i class="fa fa-folder-o">&nbsp;</i><a class="post-category-link" href="/categories/Python/">Python&nbsp;/&nbsp;</a></p><div class="post-content"><p>看了一下站点,我的思路是先把漏洞信息的网址提炼出来,再进行爬行.</p>
<p>发现有反爬,有点头疼..</p>
<p>获取url的脚本</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line">import requests</span><br><span class="line">import re #这里是模块,需要先安装</span><br><span class="line">a = 0</span><br><span class="line">j = 0</span><br><span class="line">print &quot;tips:使用前请更改headers&quot;</span><br><span class="line">try:</span><br><span class="line">for i in range(0,91800-a,20):#91800是网站数据条数..&apos;&apos;&apos;</span><br><span class="line">url = &quot;https://www.cnvd.org.cn/flaw/list.htm?max=20&amp;amp;offset=&quot;+str(a) #max=20是一页需要抓取的链接,最大值可以是100,offset是页数. 每页为(20/a)</span><br><span class="line">headers = &#123;</span><br><span class="line">&apos;User-Agent&apos;:&apos;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36&apos;,</span><br><span class="line">&apos;Cookie&apos;:&apos;__jsluid=d59b21382823d73180d617eee0a75359; bdshare_firstime=1495504097924; JSESSIONID=E061162B81F992F6BC16ABF2B7B56D42; __jsl_clearance=1496288393.119|0|G6nv7XxJeFQvtzdrAV6eu1XJxAc%3D&apos;</span><br><span class="line">&#125;#使用前请更改cookies和useragent</span><br><span class="line">code = requests.get(url,headers=headers)</span><br><span class="line">print u&apos;状态码&apos;+str(code)</span><br><span class="line">html = requests.get(url,headers=headers).content.decode(&apos;utf-8&apos;).encode(&apos;gbk&apos;)#这里.decode(&apos;utf-8&apos;).encode(&apos;gbk&apos;)可以删掉..如果要在cmd中能够显示中文得加上.</span><br><span class="line">bt = re.compile(&apos;href=&quot;/flaw/show/(.*[\u4e00-\u9fa5+])&quot;&apos;)#因为url爬出来是/flaw/show/CNVD-2017-05272 而不是带https://www.cnvd.org.cn/flaw/show/CNVD-2017-05272 所以我直接爬CNVDID</span><br><span class="line">btt=re.findall(bt,html)</span><br><span class="line">f=open(&quot;Untreated.txt&quot;,&quot;a&quot;)</span><br><span class="line">for j in range(30):</span><br><span class="line">bttt=(&apos;https://www.cnvd.org.cn/flaw/show/&apos;+btt[j]+&apos;\n&apos;).replace(&apos;&quot; title=&apos;,&apos;&apos;)#这里是存入文本. 这时候我给CNVDID加上前缀形成完整的url,因为有些链接爬下来会带有 title=,所以我顺便替换了</span><br><span class="line">f.write(str(bttt))</span><br><span class="line">j += 1</span><br><span class="line">a += 20</span><br><span class="line">print u&apos;已爬完第%d页的链接啦&apos;%(a/20)</span><br><span class="line">obuff = []</span><br><span class="line">for ln in open(&apos;untreated.txt&apos;):#这里开始是文本去重并输出到url.txt</span><br><span class="line">if ln in obuff:</span><br><span class="line">continue</span><br><span class="line">obuff.append(ln)</span><br><span class="line">with open(&apos;url.txt&apos;, &apos;w&apos;) as handle:</span><br><span class="line">handle.writelines(obuff)</span><br><span class="line">f.close()</span><br><span class="line">except:</span><br><span class="line">print u&quot;\n发生异常,爬到第%d页的时候被屏蔽了&quot;%(a/20)#因为网站cookies有限制爬行次数所以做了异常处理方便知道爬到第几次被屏蔽了..解决方法是稍等.或者换headers 还有其他方法..</span><br><span class="line"> </span><br><span class="line">获取漏洞信息脚本并存入数据库</span><br><span class="line"># -*- coding:utf-8 -*-</span><br><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line">import MySQLdb</span><br><span class="line">conn=MySQLdb.connect(host=&apos;localhost&apos;,user=&apos;root&apos;,passwd=&apos;&apos;,db=&apos;cnvd&apos;,charset=&quot;utf8&quot;)#链接数据库信息</span><br><span class="line">cursor = conn.cursor()</span><br><span class="line">f = open(&quot;url.txt&quot;,&quot;r&quot;)</span><br><span class="line">headers=&#123;</span><br><span class="line">&apos;User-Agent&apos;:&apos;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36&apos;,</span><br><span class="line">&apos;cookie&apos;:&apos;__jsluid=d59b21382823d73180d617eee0a75359; bdshare_firstime=1495504097924; __jsl_clearance=1496307201.861|0|pUxGicIFM6b4cfP475OjzLj21%2Bs%3D; JSESSIONID=7709C82CFD28247F74A0FBDF408A69A6&apos;</span><br><span class="line">&#125;</span><br><span class="line">for url in f.readlines():</span><br><span class="line">cc = url.strip()#读取文本每一行并去回车符</span><br><span class="line">html = requests.get(cc,headers=headers).content.replace(&apos;\r&apos;,&apos;&apos;).replace(&apos;\n&apos;,&apos;&apos;).replace(&apos;\t&apos;,&apos;&apos;).replace(&apos;&amp;lt;br&amp;gt;&apos;,&apos;&apos;).replace(&quot;&apos;&quot;,&quot;&apos;&apos;&quot;)#网站有很多符号,提前替换掉方便抓取内容</span><br><span class="line">z1 = re.compile(r&apos;&amp;lt;h1 &amp;gt;(.*)&amp;lt;/h1&amp;gt;&apos;)#这里是正则表达式.</span><br><span class="line">title = re.findall(z1,html)</span><br><span class="line">z2 = re.compile(r&apos;(?&amp;lt;=&amp;lt;td&amp;gt;)[^&amp;lt;]+(?=&amp;lt;/td&amp;gt;)&apos;)</span><br><span class="line">cid = re.findall(z2,html)</span><br><span class="line">z3 = re.compile(&apos;&amp;lt;td class=&quot;alignRight&quot;&amp;gt;漏洞类型&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;(.*)&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;tr&amp;gt;&amp;lt;td class=&quot;alignRight&quot;&amp;gt;URL&amp;lt;/td&amp;gt;&apos;)</span><br><span class="line">typp = re.findall(z3,html)</span><br><span class="line">z4 = re.compile(&apos;&amp;lt;td class=&quot;alignRight&quot;&amp;gt;漏洞描述&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;(.*)&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;tr&amp;gt;&amp;lt;td class=&quot;alignRight&quot;&amp;gt;漏洞类型&amp;lt;/td&amp;gt;&apos;)</span><br><span class="line">des = re.findall(z4,html)</span><br><span class="line">z5 = re.compile(&apos;&amp;lt;td class=&quot;alignRight&quot;&amp;gt;漏洞解决方案&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;(.*)&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;tr&amp;gt;&amp;lt;td class=&quot;alignRight&quot;&amp;gt;漏洞发现者&amp;lt;/td&amp;gt;&apos;)</span><br><span class="line">res = re.findall(z5,html)</span><br><span class="line">z6 = re.compile(&apos;&amp;lt;td class=&quot;alignRight&quot;&amp;gt;影响产品&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;(.*)&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;tr&amp;gt;&amp;lt;td class=&quot;alignRight&quot;&amp;gt;漏洞描述&amp;lt;/td&amp;gt;&apos;)</span><br><span class="line">rang = re.findall(z6,html)</span><br><span class="line">a = 1</span><br><span class="line">for i in range(len(title)):</span><br><span class="line">print &quot;写入中....如果停止时间过长,应该是被屏蔽了...&quot;</span><br><span class="line">a+=1</span><br><span class="line">cursor.execute(r&quot;insert into message(name,id,type,des,res,rang) values(&apos;&quot;+title[i]+&quot;&apos;,&apos;&quot;+cid[i]+&quot;&apos;,&apos;&quot;+typp[i]+&quot;&apos;,&apos;&quot;+des[i]+&quot;&apos;,&apos;&quot;+res[i]+&quot;&apos;,&apos;&quot;+rang[i]+&quot;&apos;)&quot;)#sql语句 请创好表</span><br><span class="line">conn.commit()#执行sql语句</span><br><span class="line">cursor.close()</span><br><span class="line">conn.close()</span><br><span class="line">f.close()</span><br></pre></td></tr></table></figure>
</div></article></div><div class="article"><hr><h2>版权声明</h2>| 文章作者：<a href="http://wwwuxt.cc">wwwuxt</a><br>| 文章链接：<a href="http://www.seeper.cn/2017/06/17/抓取CNVD漏洞信息并存入MYSQL数据库/">http://www.seeper.cn/2017/06/17/抓取CNVD漏洞信息并存入MYSQL数据库/</a><br>| 许可协议：<a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a><hr></div></main><footer><div class="paginator"><a class="prev" href="/2017/07/17/爬取补天公益SRC零漏洞数的网站/"><!--!= __('< PREV_POST')-->< 爬取补天公益SRC零漏洞数网站</a><a class="next" href="/2017/05/17/爬取百度权重排行榜/"><!--!= __('NEXT_POST >')-->爬取百度权重排行榜 ></a></div><div class="clearfix"></div><div class="copyright"><p id="host_by"> <a href="/atom.xml"><i class="fa fa-rss"></i></a><span id="busuanzi_container_site_pv">&nbsp;<i class="fa fa-eye">&nbsp;</i><span id="busuanzi_value_site_pv"><i class="fa fa-spinner"></i></span> times, </span><span id="busanzi_container_site_uv">&nbsp;<i class="fa fa-user">&nbsp;</i><span id="busuanzi_value_site_uv"><i class="fa fa-spinner"></i></span> times.</span><br> &copy; 2017 - 2018 <a href="http://wwwuxt.cc">wwwuxt</a>. 
 Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> &amp; <a href="https://github.com/wwwuxt/hexo-theme-artemisX" target="_blank">ArtemisX</a>.<br></p><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></footer></div><script>var _gaq = _gaq || [];
_gaq.push(['_setAccount', 'UA-108353521-1']);
_gaq.push(['_trackPageview']);

(function () {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})();
console.log('Google Analytics')
</script><script>(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https'){
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else{
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
    console.log('wwwuxt.cc')
})();
</script><script>(function(){
    var req = GetXmlHttpObject()  
    if (req == null) {  
        console.log("not support AJAX!");  
        return;  
    }
    req.onreadystatechange = function() {  
        if (req.readyState === 4 && req.status === 200) {  
            var deploy_server = req.getResponseHeader("Server");
            console.log(deploy_server)
            if(deploy_server === 'Coding Pages'){
                document.getElementById('host_by').innerHTML+='Hosted by <a href="https://pages.coding.me" style="font-weight: bold">Coding Pages</a>.'
            }
            else if(deploy_server === 'GitHub.com'){
                document.getElementById('host_by').innerHTML+='Hosted by <a href="https://pages.github.com" style="font-weight: bold">GitHub Pages</a>.'
            }
            else{
                document.getElementById('host_by').innerHTML+='Hosted by <a href="#" style="font-weight: bold">'+ deploy_server + '</a>.'
            }
        }  
    };  
    req.open('GET', document.location, true);
    req.send(null);
})();
function GetXmlHttpObject() {  
    var xmlHttp = null;  
    try {  
        // Firefox, Opera 8.0+, Safari  
        xmlHttp = new XMLHttpRequest();  
    } catch (e) {  
        // Internet Explorer  
        try {  
            xmlHttp = new ActiveXObject("Msxml2.XMLHTTP");  
        } catch (e) {  
            xmlHttp = new ActiveXObject("Microsoft.XMLHTTP");  
        }  
    }  
    return xmlHttp;  
}  </script></body></html>